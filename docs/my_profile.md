# MY PROFILE

### **Introduction:**

Hi, I’m Taranjyot Singh, an experienced Software Development Engineer with 4+ years of hands-on experience in Python development, backend systems, and full-stack web development. Proven track record of building scalable, production-grade applications leveraging cloud platforms (AWS, Azure), Kubernetes, and CI/CD automation with Jenkins. Proficient in design patterns, software architecture, functional programming paradigms, and financial data applications. Demonstrates a passion for innovation, continuous learning, and delivering high-impact solutions in fast-paced, agile environments.

In my most recent role at Anuvu, I led the development and deployment of a CI/CD pipeline using Jenkins, which streamlined our release processes and automated AWS instance provisioning. I was also responsible for building microservices that handled data transformation and analysis, achieving 87% code coverage through rigorous unit testing. I thrive in collaborative environments, working closely with cross-functional teams to bring robust software solutions to life. Additionally, I played a key role in releasing three live products and monitored the testing of over 25 games on platforms like PlayCanvas and PixiJs.

Before that, I worked at Solut Pvt. Ltd., where I designed and implemented an interactive web application using Python-Flask for on-field agents. This project involved managing over 1 million records with role-based authorization, which ensured secure access for various user roles. This experience helped me enhance my full-stack development skills, and I collaborated closely with clients to tailor the solution to their specific requirements.

I also have a strong academic background with a Master of Engineering in Quality System Engineering from Concordia University, where I honed my skills in software quality and system optimization. My earlier work included developing an AI system for handwritten digit recognition, where I achieved a 90% accuracy rate.

### **Accomplishments:**

Successfully developed and maintained 6 microservices, contributing to high-quality backend systems with extensive unit testing.  
Implemented a CI/CD pipeline using Jenkins to automate deployments, improving release cycles and reducing manual effort.  
Led data transformation projects using SAS, Pandas, and Airflow, enabling efficient data handling in microservice architectures.  
Built and optimized REST APIs for secure, scalable applications, ensuring data integrity and accessibility.  
Skills and Attributes:

I’m a proactive, results-oriented engineer who’s always looking for ways to improve processes and drive system optimization. With a strong background in object-oriented programming (OOP), microservices architecture, and cloud infrastructure like AWS, I enjoy taking on complex challenges and delivering clean, efficient code.

Additionally, I pride myself on being an excellent communicator and team player. Throughout my career, I’ve fostered a culture of collaboration by participating in peer reviews, mentoring junior developers, and working closely with QA and product teams to ensure project success. I’m passionate about learning and consistently explore new technologies and best practices to enhance my skill set.

In summary, I bring a combination of technical proficiency, problem-solving skills, and a collaborative mindset to the table. I’m eager to continue building applications that solve real-world problems while working closely with teams to deliver innovative solutions.

## **Summary of industry and domain experience based on the resume:**

### **Industry Experience:**

1. **Software Development**:
2. 4+ years of experience working as a Software Development Engineer, specializing in backend development, REST API architecture, and full-stack solutions.
3. Hands-on experience in implementing CI/CD pipelines and cloud infrastructure.
4. **Data Engineering and Data Science**:
5. Experience in working with ETL processes, data transformation, analysis (SAS, Pandas), and data science tools for microservices.
6. Worked on AI-based projects like handwritten digit recognition and emotion detection, using machine learning algorithms and OpenCV.
7. **Cloud Computing**:
8. Experience working with AWS, Azure, and cloud-based data management using tools like AWS Databricks and DataBricks Delta for big data projects.
9. **Gaming/Entertainment Industry**:
10. Worked on testing platforms for games using PlayCanvas and PixiJS, which are commonly used in the gaming and entertainment industry.
11. **Finance/Technology Industry**:
12. Managed the backend for data-driven financial platforms with role-based authorization, handling large datasets and providing secure access.
13. **Quality Control and Risk Management**:
14. Participated in a project related to quality control and risk management, specifically on design improvement of the Boeing 737 Max aircraft.

### Domain Experience:

1. **Web Development**:
2. Full-stack development using frameworks like **Django**, **Flask**, and front-end technologies like **React**, **JavaScript**, **TypeScript**, and **HTML/CSS**.
3. **Automation and CI/CD**:
4. Implemented CI/CD pipelines using tools like **Jenkins**, **Bitbucket**, **Git**, **Docker**, and **AWS** to streamline software releases and system deployments.
5. **Machine Learning and AI**:
6. Experience in machine learning, data analysis, and artificial intelligence models like emotion detection and OCR systems, leveraging Python-based libraries such as **NumPy**, **Pandas**, **SciKit-Learn**, and **TensorFlow**.
7. **Database Management**:
8. Strong command over relational and NoSQL databases like **MySQL**, **PostgreSQL**, **MongoDB**, **ElasticSearch**, and **Azure Database**.
9. **Big Data Technologies**:
10. Experience in working with big data tools such as **Apache Airflow**, **Spark**, **Hadoop**, and **PySpark** to handle large-scale data processing.
11. **Software Testing and Unit Testing**:
12. Significant experience in unit testing using **Pytest**, ensuring high code coverage and reliability in the developed software solutions.

### **Conclusion:**

My experience spans a variety of industries including **software development**, **data engineering**, **cloud computing**, **finance/technology**, and **quality control**. You are proficient in building scalable backend and full-stack applications, with strong skills in data science, automation, and cloud-based infrastructure.

### **What Drives Me:**

I’m passionate about solving complex problems and continuously improving systems to deliver better business outcomes. I thrive in collaborative, agile environments, and I’m always eager to learn new technologies and tackle new challenges. Whether it's building scalable backend systems, optimizing cloud infrastructure, or developing robust APIs, I take pride in delivering results that matter.

## **Summary of "RDBMS Analysis for Big Data using Elasticsearch"**

The research paper "RDBMS Analysis for Big Data using Elasticsearch" by Taranjyot Singh and Geetika Bhatia discusses the limitations of traditional Relational Database Management Systems (RDBMS) for handling the growing volume and complexity of big data. It introduces Elasticsearch as a powerful alternative for analyzing large datasets efficiently. Elasticsearch, a search engine built on Lucene, provides near real-time search capabilities by using techniques like indexing, denormalization, and the inverted index.

The paper explains that unlike RDBMS, which struggles with unstructured or semi-structured data, Elasticsearch is schema-less and document-oriented, allowing for faster and more flexible data retrieval. The inverted index, a core concept in Elasticsearch, enables quick searches by mapping terms to their respective documents. The use of stopword lists and other optimization techniques further enhances search speed and relevancy.

This highlights several use cases for Elasticsearch, including as a general-purpose document store, an analysis tool, an auto-completer, a spell checker, and a warning engine. They also describe how Elasticsearch distributes data across multiple nodes using shards, ensuring efficient storage and retrieval of large datasets.

The paper concludes by suggesting future improvements for Elasticsearch, such as refining the stopword list, enhancing tokenization and normalization processes, and optimizing scoring functions for better search relevancy. Elasticsearch is positioned as a robust solution for big data analytics, providing efficient, scalable, and real-time search capabilities.